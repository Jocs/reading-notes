{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843cff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "try:\n",
    "    # load environment variables from .env file (requires `python-dotenv`)\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "if \"LANGSMITH_API_KEY\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\n",
    "        prompt=\"Enter your LangSmith API key (optional): \"\n",
    "    )\n",
    "if \"LANGSMITH_PROJECT\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_PROJECT\"] = getpass.getpass(\n",
    "        prompt='Enter your LangSmith Project Name (default = \"default\"): '\n",
    "    )\n",
    "    if not os.environ.get(\"LANGSMITH_PROJECT\"):\n",
    "        os.environ[\"LANGSMITH_PROJECT\"] = \"default\"\n",
    "if \"DEEPSEEK_API_KEY\" not in os.environ:\n",
    "    os.environ[\"DEEPSEEK_API_KEY\"] = getpass.getpass(\n",
    "        prompt=\"Enter your DeepSeek API key (required if using DeepSeek): \"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f5bfd2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'è¯·æä¾›éœ€è¦ç¿»è¯‘çš„è‹±æ–‡å†…å®¹ï¼Œæˆ‘ä¼šå°½åŠ›ä¸ºæ‚¨å‡†ç¡®ç¿»è¯‘æˆä¸­æ–‡ã€‚'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"DEEPSEEK_API_KEY\"):\n",
    "    os.environ[\"DEEPSEEK_API_KEY\"] = getpass.getpass(\n",
    "        prompt=\"Enter your DeepSeek API key (required if using DeepSeek): \"\n",
    "    )\n",
    "    \n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following English into Chinese\"),\n",
    "    HumanMessage(\"Translate the following English into Chinese!\"),\n",
    "]\n",
    "\n",
    "ai_msg = llm.invoke(messages)\n",
    "\n",
    "ai_msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7265e193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! ðŸ˜Š How can I assist you today?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg = llm.invoke(\"Hello\")\n",
    "ai_msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11eb0bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Hello|!| ðŸ˜Š| How| can| I| assist| you| today|?||"
     ]
    }
   ],
   "source": [
    "for token in llm.stream(\"Hello\"):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f96d974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following from English into Chinese', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I have a dream', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following from English into {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")\n",
    "\n",
    "prompt = prompt_template.invoke({\n",
    "    \"language\": \"Chinese\",\n",
    "    \"text\": \"I have a dream\"\n",
    "})\n",
    "\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9b94a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following from English into Chinese', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I have a dream', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1b70e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'æˆ‘æœ‰ä¸€ä¸ªæ¢¦æƒ³'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.invoke(prompt)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77b2e29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_0_71cba42c-6515-448f-9095-e9eea75ae4e3', 'type': 'tool_call'}, {'name': 'add', 'args': {'x': 11, 'y': 49}, 'id': 'call_1_e8765153-97b7-4d94-859e-d04b93b5f650', 'type': 'tool_call'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='- 3 * 12 = 36  \\n- 11 + 49 = 60  ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 285, 'total_tokens': 305, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 256}, 'prompt_cache_hit_tokens': 256, 'prompt_cache_miss_tokens': 29}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3d5141a69a_prod0225', 'id': 'b0459440-c07c-43f0-a165-dea93d750fe7', 'finish_reason': 'stop', 'logprobs': None}, id='run-291a8ded-6752-4a86-972c-2ef9fd6bf61d-0', usage_metadata={'input_tokens': 285, 'output_tokens': 20, 'total_tokens': 305, 'input_token_details': {'cache_read': 256}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(x: int, y: int) -> int:\n",
    "    \"\"\"Add two numbers together.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "llm_with_tools = llm.bind_tools([add, multiply])\n",
    "\n",
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "\n",
    "print(ai_msg.tool_calls)\n",
    "\n",
    "messages.append(ai_msg)\n",
    "\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "    \n",
    "llm_with_tools.invoke(messages)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydata-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
